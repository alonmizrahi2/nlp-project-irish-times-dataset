{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Summary of the results of the models**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, DistilBertModel\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import DistilBertModel, DistilBertTokenizer, BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrishTimesDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)  # Return the length of the texts\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts.iloc[idx])  # Access the element using .iloc[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoded_inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=128,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        input_ids = encoded_inputs['input_ids'].squeeze()\n",
    "        attention_mask = encoded_inputs['attention_mask'].squeeze()\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'label': torch.tensor(label)\n",
    "        }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('data/ireland-news-headlines-cleaned-6.csv')\n",
    "df.rename(columns={'clean_headline_text': 'text', 'headline_category': 'category'}, inplace=True)\n",
    "\n",
    "df = df[['text', 'category']]  # Keep only 'text' and 'category' columns\n",
    "class_counts = df['category'].value_counts()\n",
    "\n",
    "df = df.dropna(subset=['text', 'category'])  # Remove rows with missing values in 'text' or 'category'\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Shuffle the data\n",
    "shuffled_data = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Define the train-test split ratio\n",
    "train_ratio = 0.9  # 90% for training, 10% for testing\n",
    "\n",
    "# Calculate the split index\n",
    "split_index = int(train_ratio * len(shuffled_data))\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_df = shuffled_data[:split_index]\n",
    "test_df = shuffled_data[split_index:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['news' 'culture' 'opinion' 'business' 'sport' 'lifestyle']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=6, bias=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-trained BERT model\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_model_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_classifier = nn.Linear(bert_model.config.hidden_size, df['category'].nunique())\n",
    "unique_classes = df['category'].unique()\n",
    "print(unique_classes)\n",
    "\n",
    "# Load model dicts\n",
    "bert_path = 'models/bset_model/BERT_6.pt'\n",
    "bert_model.load_state_dict(torch.load(bert_path, map_location=device))\n",
    "bert_model.to(device)\n",
    "bert_model.eval()\n",
    "bert_classifer_path = 'models/bset_model/Classifier_6.pt'\n",
    "bert_classifier.load_state_dict(torch.load(bert_classifer_path, map_location=device))\n",
    "bert_classifier.to(device)\n",
    "bert_classifier.eval()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrange the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_test = label_encoder.fit_transform(test_df['category'])\n",
    "# Create data loaders\n",
    "test_dataset = IrishTimesDataset(test_df['text'], y_test, bert_model_tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the best bert model\n",
    "BERT - 6 Classes, End-to-End, cleaned and balanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1175/1175 [04:20<00:00,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy on the best BERT Model: 0.8332224499028661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bert_model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, total=len(test_loader)):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]\n",
    "        logits = bert_classifier(pooled_output)\n",
    "        predicted_labels = logits.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "        predictions.extend(predicted_labels)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_accuracy = accuracy_score(true_labels, predictions)\n",
    "print('Test Accuracy on the best BERT Model:', test_accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------\n",
    "------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
